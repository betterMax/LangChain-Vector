 Hi, I'm Craig Smith and this is I on AI. This week I speak with Bratine Saaha, the head of Amazon's machine learning services. We talked about Amazon's growing dominance in model building and deploying AI about the company's SageMaker platform and whether anyone can compete with the behemoth. Before we begin, I want to thank our sponsor ClearML, the MLOP solution. You can check them out at clear.ml.com. In the meantime, I hope you find my conversation with Bratine as interesting as I did. Maybe start by describing your background when you came to Amazon and what you're doing at Amazon now. At Amazon, I now lead all of our AI and machine learning services, one of which is H. What we have the broadest and deepest set of capabilities. And then Brad, I was at NVIDIA, VP of Software Infrastructure, I did my PhD at Yale University and then also went to Harvard Business School. Been in drugs, been on the product side, been on the business side and now at Amazon leading all of the AI and machine learning services. And the services are platforms like SageMaker with various tools. We think of our customer persona in three broad categories. So there's one set of customers who say, give us just the optimized infrastructure and we will build a machine learning infrastructure and we'll build the machine learning models and we'll deploy it ourselves. So for them, we have what we call ML engines. These are deep learning containers, deep learning armies, frameworks like the core software components. We optimize them for a continuous infrastructure and then we provide them to customers to use. Then there's the next set of customers, which is where most customers are today who say building the ML infrastructure is undifferentiated heavy lifting. We would rather have you build infrastructure so we can focus on just doing the machine learning models. These are data science teams. And so that is where most of our customers are. And that is what Sage makes. It gives you an end to end platform, the ML infrastructure so that you can build a train and deploy machine learning models. And then we have the Mars who we give the pre-trained machine learning models as well. So you can just use API's. You can infuse intelligence into every app that you're building by just making calls to these functions, doing things like natural language processing, doing things like document processing, doing things like computer vision, image recognition kind of stuff. And we have solutions as well. So if you look at monitor on which is one of our solutions for preventive maintenance, that uses machine learning to predict when your equipment may be due for maintenance or may actually have downtime. We have things like panorama, which are solutions using computer vision for things like quality inspection and so on. So we think of them as three broad tiers. One, there are people are building their own machine learning infrastructure in the own models. The second is we build infrastructure. They build a model and the third is we build a model. So as well, they just invoke and they take the models and train it on their data set. They take the models and train. So for example, you can have pre-trained models. So you can start with some of the models. We provide this is the SageMaker layer and then the train it using the data set. So you either build models from scratch or you start with some models that we provide or you get models from the open source and then train it on the data set. I've heard from a lot of people that one of the attractions of working with Amazon SageMaker and tools like that is if you're on the Amazon Cloud, you're within that ecosystem. Is that important that kind of interoperability that happens within an ecosystem or can you be building on TensorFlow and using? We have customers today who do all of their machine learning on SageMaker, but we also have customers who do part of it and then do the remaining thing somewhere else. So for example, you could build your machine learning models on Prem and then deploy it on the cloud. You could on the other hand train your models in the cloud and then deploy them on Prem. So we have customers of all kinds and it's important for us to enable that so that customers have the choice and our container formats are open source. So you know exactly how you need to build your stuff. So customers can do part of the machine learning in the cloud on Adeson SageMaker and then do the remaining thing on Prem or somewhere they have the full freedom to do that. What is the difference between the Amazon ecosystem and say the Google ecosystem or the Microsoft ecosystem where you have in each case you have frameworks and then platforms and cloud integrations and all of the things that you can do. So you can have a lot of questions and all of that. It's hard from outside to understand whether one is pointed more towards industry, one is pointed more towards search or whether they're fairly interchangeable at this point. The vast majority of machine learning in the cloud happens on the west, the vast majority. And so the next question is why does the vast majority happen? And that is because of a variety of reasons one is machine learning does not exist in isolation machine learning is built on the compute and storage and data services that we have. And when you look at compute storage and database and analytic services, we have by far the most advanced most broad set of services includes city and all of that. So that is one reason. The second is when you again look at machine learning services that depth and breadth of our capabilities from model building to natural language processing to computer vision to industrial monitoring and all of that. We have the broadest and deepest set of services by far that enables customers to get their work done. And then the other thing I would also say is if you look at Amazon as a company at our investments in machine learning, we have been investing in machine learning for more than 20 years. In fact, you look at Amazon Alexa and Amazon go Amazon.com with recommendations. We have been deploying machine learning at scale for a long time. And so what we have done at was is taken that deep expertise and made it available to our customers. And then when you look at performance when you look at the performance of open source frameworks like TensorFlow and PyTorch, these frameworks run fastest on AWS. So if you look at third party sites and third party analysts reports and all that, they will tell you that in terms of the breadth of features in terms of the breadth of capabilities, we have a lot more. And that is what attracts a lot more customers and our machine learning services AI services like Sage maker, they're one of the fastest growing services in AWS history. And so the key factors are the breadth and depth of our machine learning services. Second machine learning doesn't exist in isolation. It requires this foundation of compute and storage and database and analytics where we have the most capable services. And then the fact that we are talking to the most customers because most customers users allows us to iterate very quickly and get more capabilities out and the speed of innovation. So I think these are the most important factors, but a more machine learning happens in AWS than any of it is. There is an explosion of ML ops startups right now who are they all seem to claim to be ended, but they typically take one part of the ML ops pipeline and focus on that. Is there room for smaller startups to develop platforms and tools when there's something like Sage maker that already exists and one of the things I hear from the ML ops people is yes, Sage makers there, people use Sage maker because they're on AWS, but Sage maker is a broad brush tool. It doesn't have a lot of the granularity for specific use cases that our ML ops platform has not to get into the he said she said, but is there some merit to that is there room for these new ML ops companies. This is a very broad space right now that said if you look at the breadth of customers that are using machine learning on AWS and on Sage maker as I said, it's one of the fastest growing services in AWS history. We have more than 100,000 customers using these services and they're being used in every domain in financial services in healthcare media entertainment and so on coke industries they use a service monitor on that uses machine learning to detect. vibrations and predict equipment failures and they have been able to save a lot of downtime geogia pacific uses it to improve paper quality they use it to predict the pace at which the paper rolls should be operating and they have been able to reduce paper test by 40% then you have healthcare companies like AstraZeneca and Philips that are using our machine learning services then you've into it that uses a machine learning services for apps like mint and double tax and so on. So given the breadth of customers that are using our machine learning services they're being used for pretty much every use case you can think about and that is why having an end to end platform is so important because you want to have into the disability you want to convey to the entire end to end process so sports media software financial industry healthcare all of them are now doing machine learning on AWS using Sage maker or AI services and when you say machine learning how much of that is deep learning pretty good amount of that is deep learning and then amount of deep learning keeps on increasing we are seeing customers moving more and more towards using deep learning and most sophisticated models it has been increasing over the last. It's primarily supervised learning it's it's a combination of both we do see on supervised learning as well little bit of reinforcement learning but I think more people use supervised learning today on our services. Sage maker the infrastructure product it has a data prep end and it has deployment and monitoring and I was talking earlier about these ML ops companies there's one of them layer with label box and when I've spoken to label box Sage maker always comes up and their argument is that they focus entirely on the labeling process the iterative process the discovery of bias and mitigation and all of that to improve data quality. The structure data and unstructured data could be images could be text could be audio and videos and so on that is the data labeling comes in and so for that we have ground rule and ground road provides a fully turn key experience you as a customer just come in hand the data ground through does all of the data labeling and then hands the label data back to you and we often use machine learning models to automate the data labeling now as part of that we have quality checks to make sure that the labeling has been done well and then we have tools like Sage maker clarify that lets you do bias detection and let you do bias detection not just in your data it lets you do bias detection even in your models. So we have a very holistic suite between structured data and unstructured data one structure that is where you're looking at data labeling we do the data labeling we do quality checks then you can do bias analysis and then once your data is prepared then you send this on for model building and model deployment and so on. And then in model deployment we have model monitoring so once your models have been deployed you do that now the benefit of having this end to end platform which is very comprehensive data labeling platform included as part of this whole thing is that once you have deployed the model into production you want to monitor it and then if there are some mis predictions you want to be able to come back and retrain your model now because it's all in a single platform you can look at where did the model go wrong pick up those kinds of data. Relabel it and then retrain it and that is why customers say want to be in a platform where I can get the data labeling through the model deployment and in data labeling we actually have a lots of modalities so we have audio we have video we have text we have LIDAR customers can build their own data labeling workflows they can choose from three different kinds of workforces so we have our own public crowd workforce then they can bring their own workforce and then we have a lot of work for us. So we have a lot of work for us and then we have a number of vendors so they can contract out to those vendors so it's a very comprehensive data labeling solution that includes not just labeling but also quality checks so people get good label data and then of course doing bias analysis and so on with Sage maker clarifying your data. So what we are also saying is we see customers do a lot more what we would call multi model data analysis for example in the financial industry they want to be able to combine both tabular data and text data for example financial industry has been traditionally using tabular data but now they want to analyze things like a CC forms and so on and so this ability to be able to process both tabular data and unstructured data do data labeling and this other one is something that's very valuable to customers. So is there a cottage industry of people that are experts at Sage maker who are hired out as consultants or does Amazon have that service so that they don't have to start from scratch and do tutorials and figure out how Sage is doing. Sage maker works and as you have a team of consultants to come in and help. So we have a variety of resources so we have solution architects that help customers we have ML solutions lab where we have data scientists work together with customers to bring their models to production. We have a lot of documentation available. We have a number of other customers size and GSI system indicators global system indicators that help customers get started and also we are constantly focusing on making it easy to do. So we recently launched a part of Sage maker that we call Sage maker can was that's a no code solution for doing machine learning you don't have to write a single line of code. You bring your data and the system automatically does the data preparation for you automatically create models for you and then it will deploy the models for you. So we've been very pleased to see how many people have started using that so there are a number of things we are doing on the one hand making it easier to use a services at the product level through all of these innovations then having a lot more documentation and collateral lot of tutorials lot of examples use cases then our own solution architects ML solutions labs we have the machine learning university where all of the machine learning courses that we use for training Amazon engineers are now available for free to everyone then we partner with online education sites like Coursera where we have the practical applications of data science course with Andrew and we use that to help customers get started on Sage maker. So there's multiple things that we are doing from the product education collateral ML solutions lab solution architects to help customers get started. In your job you describe the three layers where do you spend most of your time where is the most innovation happening is it at the infrastructure level we have a lot of innovation happening at all three levels and a lot of growth happening across all of these services the AI services are being used by customers in very interesting ways so there you don't need lot of machine learning expertise to get started so these are more like solutions. So we have customers like Anthem who have been able to automate almost 80% of the claims insurance process we have customers like discovery were using our Amazon personalized to provide a much more personalized experience what kind of shows you would like we have coke industries using monitron for industrial maintenance then we have into it that's using transcribe for call center intelligence. So we are seeing broad growth across all the three layers now Sage maker is one of the fastest growing services in the history that's what most of customers have used but we are seeing growth in all three areas and very robust growth in all three layers. Okay, my last question is on the models in the APIs available you have computer vision and natural language processing and things like that what's the newest model that you're making available we are adding a lot of machine learning for DevOps if you're running cloud services automatically detecting anomalies so that is new DevOps guru we have services for forecasting so we have a very broad collection and we are constantly innovating we're looking for what we are doing. What customers want looking for what customers need and just constantly it's reading on those. That's it for this episode I want to thank Broughton for his time and invite you to read a transcript of the conversation on our website I on AI that's EY E hyphen O N dot AI. I want also to thank our sponsor clear ml the ml up solution that you can try out for free at cllear dot ml and remember the singularity may not be near but AI is about to change your world so pay attention. .