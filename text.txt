 Supermarket AI offers recipe for mom's famous mustard gas. An AI from New Zealand grocery chain gave one user a recipe for an aromatic water mix that included bleach and ammonia as ingredients. If you don't know if you mix bleach and ammonia, it would create chlorine gas. The world, the AI ethics world, the AI critics world is outraged. This is a clear example of how the deployment of large language models in an uncontrolled fashion can harm people. Harm, harm, let's say the word 50 billion times until we get what we want. It's a magic word, as you know. This has been spread around a little bit and I bet you, I bet you that five years from now, you will hear people saying that the risks of LLM, the risks of deploying AI can be clearly seen in the example because this one, a harmless recipe, but made this chlorine gas recipe and suggested it to a user. Now, if you hear that, let's call them markers of a grift. It is a headline that agrees with what you want to say or what you think gets you a lot of clout and clicks or what you must say in order for your job security, if your job security is things like advising companies or governments on the safety of AI, your job security depends on that. So you'll just retweet this article and be outraged about it. Let's actually look into it, will we? So this is a grocery chain that made a bought and the bought, you can tell it what ingredients you have and it makes you a recipe. Now, in this case, what would you expect from this headline? I would expect that I type in, you know, I have these things and it, for some reason, includes bleach in the monias, you know, at that and it gives me something really dangerous when I was actually looking for recipe. Okay, let's look at the actual tweet. I asked the recipe maker what I could make if I only had water, bleach and the monia. And it has suggested making a deadly chlorine gas. Ah, okay, let's look at this recipe. It literally lists the ingredients that you gave it and it says in a large picture, pour the ammonia and bleach and slowly add water and stir. You gave it these ingredients. You said, I want to make a recipe that includes bleach in the monia and it gave you the simplest recipe that includes bleach in the monia and you somehow complain about it. This is maximum intellectual dishonesty, not to try it out. The Liam Hayer here, cool, like try it out, think like, okay, you can make it do this. Obviously, a bought that's prompted to make a recipe from any sort of ingredients will make recipes from ingredients, but the journalist framing it as this on top of that the AI ethics people framing it like they do, probably not even having read the article. Maximum dishonest, like come on. It's an entirely different thing than you're suggesting what happened. Of course, you can make the argument if the person comes with inappropriate ingredients, you should say something, but can you really make an argument that anyone is harmed here? Clearly, nobody who is actually looking for a recipe is being suggested the chlorine gas mix and nothing here has ever demonstrated that if you come with appropriate ingredients that it gives you a chlorine gas mix. But as I said, you can bet that this argument, this example right here in its dishonest form, will go right before hearings and Congress, governmental bodies, EU commissions and whatnot, it will just be peddled and peddled and peddled. That's the nature of the grifters of AI ethics and AI criticism. The article here goes on and says it seems like we've given it bleach as an ingredient, then it came back with a recipe that included bleach, and then they criticize it that even if they come with normal ingredients, the recipe comes out utterly disgusting. So then that's the criticism. If you have actual ingredient, sometimes it makes you a recipe that's not very good. And then people find like weird edge cases. I'm sorry, people. Nobody is harmed. The only times it outputs something that's harmful is when people deliberately input things to make it output that something is harmful. They're kind of making the anti-point to what they want to make. Now obviously the company has been going like, and there's now restricting the inputs and so on. Did you just go out and be like, screw it? So what I done is I actually made my own AI that is I have to say very, very dangerous. So I made my own and it's right here. I had to use torch. So this is raw pie torch. The frameworks, they didn't accommodate the complexity of my AI. So this is the recipe maker right here. So we can try it out. Let's say, so the model, and I give it ingredients like I give it apple and mustard. So what does it say? Let's see. Mixed together apple. That's disgusting. Oh my god. How could this happen? This AI is to, okay, let's see. Let's say nails and big chunks of wood. This is dangerous. This is how like the AI just suggested me a recipe with nails in it. Clearly I have demonstrated the dangers of AI right here. That's why the license on this repository you can find it on my GitHub. It's linked is the obviously I'm going to go with the open rail license because that's the ethical license. Right. I will did the model is super duper dangerous. And you know, you can you can use it but there are restrictions in order to keep it safe. So it's the recipe AI. You cannot use it to make recipes because it's just I've you know, I the article I was skeptical. Now I'm convinced. Yeah, try out the model not to make recipes though. But you know, I let it share this around and please, please stay safe. Please the world's become dangerous.